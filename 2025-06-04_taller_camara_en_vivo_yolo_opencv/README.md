# üß™ Taller 48 - Detecci√≥n de Objetos en Tiempo Real con YOLO y Webcam


üìÖ Fecha  

2025-06-04 ‚Äì Fecha de asignaci√≥n

2025-06-15 ‚Äì Fecha de realizaci√≥n

2025-06-24 ‚Äì Fecha de entrega


----------

### üîç Objetivo del taller

Conectar la c√°mara web del PC y procesar el video en tiempo real utilizando **Python, OpenCV y YOLO** para aplicar filtros visuales y realizar detecci√≥n de objetos en vivo.  
Este taller combina t√©cnicas de visi√≥n artificial cl√°sica con modelos de detecci√≥n basados en aprendizaje profundo.

----------

### üîπ Actividades por entorno

Este taller se realiza **exclusivamente en Python (local)**, utilizando `opencv-python` y un modelo preentrenado de YOLO (por ejemplo, **YOLOv5 o YOLOv8** de `ultralytics`) o `cv2.dnn`.

----------

## üíª Python (Ejecuci√≥n local con webcam)

**Herramientas necesarias:**

-   opencv-python
    
-   numpy
    
-   ultralytics (o) cvlib (o) cv2.dnn (seg√∫n la versi√≥n de YOLO usada)
    

----------

**Pasos a implementar:**

-   Capturar video en tiempo real con `cv2.VideoCapture(0)`.
    
-   Leer frame por frame en un bucle.
    
-   Aplicar filtros b√°sicos:
    
    -   Escala de grises (`cv2.cvtColor`)
        
    -   Binarizaci√≥n (`cv2.threshold`)
        
    -   Detecci√≥n de bordes (`cv2.Canny`)
        
-   Integrar **YOLO** para detecci√≥n de objetos:
    
    -   Utilizar **YOLOv5** o **YOLOv8** con `ultralytics` o `cv2.dnn`.
        
    -   Dibujar cajas junto con nombre de la clase y la confianza.
        

----------

## **Resultados:**

-   Ventana original con detecci√≥n de objetos.
    
-   Ventanas paralelas mostrando los filtros aplicados.
    
### **Gif Sin Filtros:**
![Imagen GIF animado](https://github.com/JuanDanielRamirezMojica/computacion-visual/blob/main/2025-06-04_taller_camara_en_vivo_yolo_opencv/resultados/GifSinFiltro.gif?raw=true)

----------

**Controlar la aplicaci√≥n con teclado (`cv2.waitKey`)**:

-   Cambiar entre filtros.
    
-   Pausar o reanudar.
    
-   Guardar una imagen procesada o capturar un video corto.
 
### **Gif Binarizaci√≥n:**
![Imagen GIF animado](https://github.com/JuanDanielRamirezMojica/computacion-visual/blob/main/2025-06-04_taller_camara_en_vivo_yolo_opencv/resultados/GifFiltroBinarizacion.gif?raw=true)


 
### **Gif Escala de Grises:**
![Imagen GIF animado](https://github.com/JuanDanielRamirezMojica/computacion-visual/blob/main/2025-06-04_taller_camara_en_vivo_yolo_opencv/resultados/GifFiltroEscalaGrises.gif?raw=true)



### **Gif Canny:**
![Imagen GIF animado](https://github.com/JuanDanielRamirezMojica/computacion-visual/blob/main/2025-06-04_taller_camara_en_vivo_yolo_opencv/resultados/GifFiltroCanny.gif?raw=true)



----------

## üåü Bonus

-   Contar el n√∫mero de personas u objetos detectados en tiempo real.
    
-   Aplicar una acci√≥n condicionada, por ejemplo, **cambiar el filtro si se detecta una persona**.
   

### **Gif Din√°mico / Bonus:**
![Imagen GIF animado](https://github.com/JuanDanielRamirezMojica/computacion-visual/blob/main/2025-06-04_taller_camara_en_vivo_yolo_opencv/resultados/GifFiltroDinamico.gif?raw=true)


‚úÖ **Acciones Condicionales**:  
El taller implementa un modo din√°mico en el que, si se detecta al menos una Persona en el fotograma, se aplica autom√°ticamente el filtro Canny. De lo contrario, se deja el fotograma sin filtrar.

‚úÖ **Conteo en Tiempo Real**:  
En cada fotograma se muestran tanto el n√∫mero de personas detectadas como el nombre del filtro vigente, aumentando as√≠ el valor informativo y el control de lo que ocurre frente a la c√°mara en todo momento.

Este bonus proporciona una capa de interactividad y an√°lisis en vivo, aumentando as√≠ el inter√©s pedag√≥gico y el aprendizaje de las T√©cnicas de Visi√≥n Artificial junto con el modelo de detecci√≥n de objetos.





### **Gif Completo:**
![Imagen GIF animado](https://github.com/JuanDanielRamirezMojica/computacion-visual/blob/main/2025-06-04_taller_camara_en_vivo_yolo_opencv/resultados/GifCompleto.gif?raw=true)

----------


## üîπ Fragmento de c√≥digo relevante:

```python
# Loop principal
filter_option = 0
running = True

  

while  running:
	ret, frame = cap.read()
	if  not  ret:
		print("Error: no se pudo leer el fotograma.")
		break
		
	# Aplicar filtro
	filtro = aplicar_filtros(frame.copy(), filter_option)
	# Realizar detecci√≥n de objetos
	resultados = model(frame)
	detections = resultados[0]
	  
	# dibujar detecciones en el frame original
	deteccion = detections.plot()

	#Mostrar varias ventanas
	cv2.imshow("Original con deteccion", deteccion)
	cv2.imshow("Filtro Aplicado", filtro)

	# Control con teclado
	key = cv2.waitKey(1) & 0xFF
	if  key == ord('q'): # presiona q para salir
	running = False
	elif  key == ord('f'): # f para cambiar de filtro
	filter_option = (filter_option + 1) % 4
	elif  key == ord('s'): # guardar captura
	cv2.imwrite("captura.jpg", deteccion)
	print("Captura guardada.")


cap.release()
cv2.destroyAllWindows()
```

üß© Prompts Usados

- _Refactoriza este c√≥digo "...."_
-  "Mejora la redacci√≥n de estos parrafos: "..".


----------

## üìö Entrega
```
2025-06-04_taller_camara_en_vivo_yolo_opencv/
 ‚îî‚îÄ‚îÄ python/
 ‚îî‚îÄ‚îÄ resultados/
 ‚îî‚îÄ‚îÄ README.md 
```

### üß© Prompts Usados

- _Refactoriza este c√≥digo "...."_
-  "Mejora la redacci√≥n de estos parrafos: "..".

----------




## üí¨ Reflexi√≥n Final

En el taller, implementar la detecci√≥n de objetos en vivo junto con el procesamiento de im√°genes en tiempo real fue una experiencia muy enriquecedora.
Combinamos tanto t√©cnicas de visi√≥n artificial cl√°sica ‚Äîcomo la aplicaci√≥n de filtros en escala de grises y detecci√≥n de bordes‚Äî con el poder de los modelos de detecci√≥n basados en aprendizaje profundo (YOLO).

Durante las pruebas, el modelo fue capaz de detectar con seguridad algunos de los objetos presentes en el lugar, como personas, botellas o sillas, dibuj√°ndoles un marco junto con el nombre de la clase y el puntaje de confianza. Esto proporciona una aplicaci√≥n pr√°ctica muy √∫til en el an√°lisis de video en entornos din√°micos.

Sin embargo, tambi√©n aparecieron algunos retos, como detecciones err√≥neas o poca estabilidad en algunos fotogramas, que muestran que el modelo puede confundir determinados grupos de p√≠xeles, o que el rendimiento puede descender en entornos con poca luz o muchos movimientos. Esto pone en evidencia que el modelo tiene limitaciones y que el resultado final puede optimizarse aumentando el conjunto de datos de entrenamiento, modificando los umbrales de detecci√≥n, o aumentando la resoluci√≥n de la c√°mara.

----------

## üõ† Criterios de evaluaci√≥n

‚úÖ Captura funcional desde la c√°mara web en tiempo real.  
‚úÖ Aplicaci√≥n de al menos **2 filtros** junto con detecci√≥n de objetos con **YOLO**.  
‚úÖ Ventanas sincronizadas mostrando cada resultado.  
‚úÖ Visualizaci√≥n adecuada de cajas, nombre de clases y confianza.  
‚úÖ C√≥digo funcional, modular y adecuadamente comentado.  
‚úÖ `README.md` completo, con explicaci√≥n, evidencias visuales (GIF) y prompts.  
‚úÖ Commits descriptivos en Ingl√©s.
