# üß™ Taller - Interfaces Multimodales: Control por Voz y Gesto

## üìÖ Fecha
`2025-07-20`    

---

## üéØ Objetivo del Taller

Desarrollar una interfaz multimodal que combine reconocimiento de voz y detecci√≥n de gestos con las manos para controlar elementos visuales en tiempo real. Se busca explorar la integraci√≥n de m√∫ltiples modalidades de entrada (voz y gestos) para crear experiencias de usuario m√°s naturales e intuitivas, aplicables en sistemas de realidad aumentada, interfaces de usuario avanzadas y control de aplicaciones.

---

## üß† Conceptos Aprendidos

- Detecci√≥n de gestos con las manos usando `MediaPipe`.
- Reconocimiento de voz en tiempo real con `SpeechRecognition`.
- Integraci√≥n multimodal para control de interfaces.
- Programaci√≥n concurrente con `threading` para manejo simult√°neo de m√∫ltiples entradas.
- Renderizado en tiempo real con `pygame`.
- Combinaci√≥n de comandos de voz con gestos para acciones espec√≠ficas.
- Manejo de estado compartido entre diferentes hilos de ejecuci√≥n.

---

## üîß Herramientas y Entornos

- Python (local)
- `mediapipe` para detecci√≥n de gestos de manos
- `opencv-python` para captura y procesamiento de video
- `speechrecognition` para reconocimiento de voz
- `pyaudio` para captura de audio
- `pygame` para renderizado gr√°fico
- `numpy` para manipulaci√≥n de datos
- `python-osc` para comunicaci√≥n (opcional)

---

## üìÅ Estructura del Proyecto

```
2025-07-20_taller_interfaces_multimodales_voz_gesto/
‚îú‚îÄ‚îÄ taller_interfaces_multimodales.ipynb  # Notebook principal con el c√≥digo del taller
‚îú‚îÄ‚îÄ README.md                              # Documentaci√≥n del taller
```

---

## üß™ Implementaci√≥n

### üîπ Etapas realizadas

1. **Configuraci√≥n del Entorno**: Instalaci√≥n de las librer√≠as necesarias para detecci√≥n de gestos, reconocimiento de voz y renderizado.

   ```python
   pip install mediapipe opencv-python speechrecognition pyaudio python-osc numpy pygame
   ```

2. **Detecci√≥n de Gestos**: Implementaci√≥n de detecci√≥n de gestos de manos usando MediaPipe para reconocer patrones espec√≠ficos como mano abierta y dos dedos levantados.

   **C√≥digo relevante:**
   ```python
   import mediapipe as mp
   
   mp_hands = mp.solutions.hands
   hands = mp_hands.Hands()
   
   def detectar_gestos():
       # Detecci√≥n simple basada en landmarks
       if results.multi_hand_landmarks:
           dedos_arriba = 0
           # L√≥gica para contar dedos levantados
           estado_gesto["mano_abierta"] = dedos_arriba >= 4
           estado_gesto["dos_dedos"] = dedos_arriba == 2
   ```

3. **Reconocimiento de Voz**: Implementaci√≥n de captura y reconocimiento de comandos de voz en espa√±ol para controlar la aplicaci√≥n.

   **C√≥digo relevante:**
   ```python
   import speech_recognition as sr
   
   def reconocer_comando():
       r = sr.Recognizer()
       with sr.Microphone() as source:
           audio = r.listen(source, timeout=3)
           texto = r.recognize_google(audio, language="es-ES")
           return texto.lower()
   ```

4. **Integraci√≥n Multimodal**: Combinaci√≥n de gestos y comandos de voz para ejecutar acciones espec√≠ficas en la interfaz visual.

   **L√≥gica de control:**
   - **Mano abierta + comando "cambiar"**: Cambia color a azul
   - **Mano abierta + comando "rojo"**: Cambia color a rojo  
   - **Mano abierta + comando "verde"**: Cambia color a verde
   - **Dos dedos + comando "mover"**: Mueve el objeto
   - **Dos dedos + comando "ocultar/mostrar"**: Controla visibilidad

5. **Renderizado en Tiempo Real**: Visualizaci√≥n de los resultados de la interacci√≥n multimodal usando pygame con elementos gr√°ficos que responden a los comandos.

   **C√≥digo relevante:**
   ```python
   import pygame
   
   # Renderizar escena basada en estado actual
   if mostrar:
       pygame.draw.circle(pantalla, color, (x, 300), 50)
   texto = font.render(f"Comando: {ultimo_comando}", True, (255, 255, 255))
   ```

6. **Programaci√≥n Concurrente**: Uso de hilos para manejar simult√°neamente la detecci√≥n de gestos, reconocimiento de voz y renderizado de la interfaz.

   **C√≥digo relevante:**
   ```python
   import threading
   
   threading.Thread(target=detectar_gestos, daemon=True).start()
   threading.Thread(target=escuchar_voz, daemon=True).start()
   ```

### üîπ Funcionalidades Implementadas

- **Detecci√≥n de gestos de mano**: Reconocimiento de mano abierta y dos dedos levantados
- **Reconocimiento de voz**: Captura y procesamiento de comandos en espa√±ol
- **Control multimodal**: Combinaci√≥n de gesto + voz para acciones espec√≠ficas
- **Interfaz visual responsiva**: C√≠rculo que cambia color, posici√≥n y visibilidad
- **Feedback visual**: Mostrar el √∫ltimo comando reconocido en pantalla
- **Ejecuci√≥n concurrente**: Manejo simult√°neo de m√∫ltiples entradas

---

## üìä Resultados Visuales

**Interfaz Multimodal en Funcionamiento:**
- Ventana de c√°mara mostrando detecci√≥n de gestos de mano
- Interfaz gr√°fica con c√≠rculo que responde a comandos
- Texto mostrando el √∫ltimo comando de voz reconocido

**Comandos Implementados:**
- "cambiar" + mano abierta ‚Üí Cambio de color a azul
- "rojo" + mano abierta ‚Üí Cambio de color a rojo
- "verde" + mano abierta ‚Üí Cambio de color a verde
- "mover" + dos dedos ‚Üí Movimiento del objeto
- "ocultar" + dos dedos ‚Üí Ocultar objeto
- "mostrar" + dos dedos ‚Üí Mostrar objeto

---

## üí¨ Reflexi√≥n Final

Las interfaces multimodales representan el futuro de la interacci√≥n humano-computadora, permitiendo formas m√°s naturales e intuitivas de controlar aplicaciones. Este taller demuestra c√≥mo combinar m√∫ltiples modalidades de entrada (voz y gestos) para crear experiencias de usuario ricas y vers√°tiles.

Los principales desaf√≠os incluyen la sincronizaci√≥n entre diferentes modalidades, el manejo de ruido en el reconocimiento de voz, la precisi√≥n en la detecci√≥n de gestos, y la programaci√≥n concurrente para manejar m√∫ltiples entradas simult√°neamente. Sin embargo, las bibliotecas modernas como MediaPipe y SpeechRecognition facilitan significativamente la implementaci√≥n de estas tecnolog√≠as.

Las aplicaciones potenciales incluyen interfaces de realidad aumentada, control de presentaciones, sistemas de dom√≥tica, asistentes virtuales avanzados, y aplicaciones de accesibilidad para usuarios con diferentes capacidades motoras.