# üß™ Taller  47 - Detecci√≥n de Objetos en Tiempo Real con YOLO y Webcam

üìÖ Fecha

2025-06-04 ‚Äì Fecha de asignaci√≥n

2025-06-15 ‚Äì Fecha de realizaci√≥n

2025-06-24 ‚Äì Fecha de entrega

----------

### üîç Objetivo del taller

Implementar detecci√≥n de objetos en tiempo real utilizando un modelo **YOLOv5 o YOLOv8** preentrenado, capturando la se√±al de la c√°mara web del computador.  
Se busca explorar la eficiencia y precisi√≥n del modelo, as√≠ como medir el desempe√±o del sistema en vivo (FPS).

Este taller combina t√©cnicas de visi√≥n artificial junto con el modelo de detecci√≥n de objetos, aumentando as√≠ el inter√©s pedag√≥gico y el aprendizaje de nuevos m√©todos de an√°lisis de video en tiempo real.

----------

### üîπ Actividades por entorno

Este taller se desarrolla **exclusivamente en Python (entorno local)**, utilizando:

-   `opencv-python`
    
-   `ultralytics` (o `torch`)
    
-   `numpy`
    

----------

## üíª Python (Ejecuci√≥n local con webcam)

**Herramientas necesarias:**

-   opencv-python
    
-   ultralytics
    
-   torch
    
-   numpy
    

----------

### Pasos a implementar:
-   Instalar las dependencias necesarias:
`pip install ultralytics opencv-python` 

-   Importar librer√≠as y cargar el modelo:

``` python
from ultralytics import YOLO import cv2, time
model = YOLO('yolov8n.pt')` 
```

-   Capturar video en tiempo real:
    
```python
cap = cv2.VideoCapture(0)` 
```
-   En cada frame:
    
    -   Medir el inicio del fotograma.
        
    -   Realizar detecci√≥n con `model.predict(source=frame, stream=False)`.
        
    -   Filtrar opcionalmente seg√∫n el modo vigente.
        
    -   Dibujar las cajas, nombre de la detecci√≥n y puntajes de confianza.
        
    -   Calcular e imprimir el **FPS**.
        
    -   Mostrar el nombre del filtro vigente junto con el FPS.
        
-   Visualizar el resultado con `cv2.imshow()`.
    
-   Utilizar teclas:
    
    -   **q** ‚Üí salir
        
    -   **f** ‚Üí cambiar el filtro de detecci√≥n (sin filtro, person, cat, cell phone)

----------
## üåü Bonus

‚úÖ Implementamos un modo din√°mico:

-   La aplicaci√≥n permitir√° **alternar** con F el modo de filtrado de detecciones:
    
    -   Sin Filtro
        
    -   Filtrar Persona
        
    -   Filtrar Gato
        
    -   Filtrar Celular
        
-   Por cada fotograma se muestran:
    
    -   El n√∫mero de detecciones.
        
    -   El nombre del filtro vigente.
        
    -   El **FPS**.
        

Este bonus proporciona una capa de interactividad y an√°lisis en vivo, aumentando as√≠ el inter√©s pedag√≥gico y el aprendizaje de las T√©cnicas de Visi√≥n Artificial junto con el modelo de detecci√≥n de objetos.

----------

## üîπ Fragmento de c√≥digo relevante:

```python
# Real-time Object Detection with YOLOv8 and OpenCV
import  cv2  # Se usa OpenCV para la captura de video y visualizaci√≥n
import  time  # Se usa time para calcular el FPS
from ultralytics import YOLO #Se usa la librer√≠a ultralytics para cargar el modelo YOLOv8

# Carga el modelo (YOLOv8n)
model = YOLO("yolov8n.pt")

# Filtra opcionalmente seg√∫n las clases que deseas detectar
filter_labels = [None, "person", "cat", "cell phone"]

# Inicializa la captura de video
cap = cv2.VideoCapture(0)

if  not  cap.isOpened():
print("Error: no se pudo acceder a la c√°mara.")
cap.release()
exit(1)


print("Presiona 'q' para salir")
print("Presiona 'f' para cambiar el modo de filtrado")

# Filtrado activado o desactivado
filter_index = 0

# Loop principal
try:
	while  True:
		inicio = time.time()
		ret, frame = cap.read()
		if  not  ret:
			print("Error: no se pudo leer el fotograma.")
			break

		# Realiza detecci√≥n de objetos en el fotograma
		resultados = model.predict(source=frame, stream=False)
		detections = resultados[0]

		# Filtra seg√∫n el modo vigente
		if  filter_labels[filter_index] is  not  None:
			filter_name = filter_labels[filter_index]
			filtered_boxes = []
			for  box  in  detections.boxes:
				class_id = int(box.cls.item()) # el id de la detecci√≥n
				class_name = model.names[class_id] # nombre de la detecci√≥n

				if  class_name == filter_name:
					filtered_boxes.append(box)
			detections.boxes = filtered_boxes

		# Dibuja las detecciones en el fotograma
		annotated = detections.plot()

		# Calcula el FPS
		fin = time.time()
		fps = 1.0 / (fin - inicio)
		fps_text = f"FPS: {fps:.2f}"
		
		# Muestra el modo de filtrado
		modo = filter_labels[filter_index]
		modo_txt = f"Filtro: {modo  or  'Sin Filtro'}"  

		color = (0, 255, 0) if  filter_index == 0  else (0, 0, 255)
		cv2.putText(annotated, modo_txt, (20, 30),
			fontFace=cv2.FONT_HERSHEY_SIMPLEX,
			fontScale=1, color=color, thickness=2)

		cv2.putText(annotated, fps_text, (20, 60),
			fontFace=cv2.FONT_HERSHEY_SIMPLEX,
			fontScale=1, color=color, thickness=2)

		# Muestra el resultado
		cv2.imshow("Deteccion en Tiempo Real", annotated)
		# Control con teclado
		key = cv2.waitKey(1) & 0xFF
		if  key == ord('q'): # presiona q para salir
			break
		elif  key == ord('f'): # f para cambiar el filtro
			filter_index = (filter_index + 1) % len(filter_labels)
			print(f"Filtro cambiado a: {filter_labels[filter_index] or  'Sin Filtro'}")

finally:
	cap.release()
	cv2.destroyAllWindows()
```

### üß© Prompts Usados

- _Refactoriza este c√≥digo "...."_
-  "Mejora la redacci√≥n de estos parrafos: ".."
- ¬øC√≥mo mido el desmepe√±o del programa?
 
----------

## üìö Entrega
```
2025-06-04_taller_yolo_deteccion_webcam_tiempo_real/
 ‚îî‚îÄ‚îÄ python/
 ‚îî‚îÄ‚îÄ resultados/
 ‚îî‚îÄ‚îÄ README.md` 
```
----------

## üõ† Criterios de evaluaci√≥n

‚úÖ Carga funcional de YOLOv5 o YOLOv8.  
‚úÖ Captura en tiempo real desde la c√°mara web.  
‚úÖ Detecci√≥n visual con cajas, nombre de clases y puntajes de confianza.  
‚úÖ C√°lculo de tiempo de inferencia por frame (FPS).  
‚úÖ Bonus.
‚úÖ C√≥digo limpio, modular y adecuadamente comentado.  
‚úÖ `README.md` completo con explicaci√≥n, evidencias visuales (GIF) y prompts.  
‚úÖ Commits descriptivos en Ingl√©s.

