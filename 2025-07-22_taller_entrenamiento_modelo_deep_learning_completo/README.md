# ğŸ¤– Taller - Entrenamiento de Modelo Deep Learning Completo

## ğŸ“… Fecha
`2025-07-22`

---

## ğŸ¯ Objetivo del Taller

Implementar un pipeline completo de entrenamiento de modelos de deep learning utilizando PyTorch, explorando diferentes arquitecturas de redes neuronales para clasificaciÃ³n de imÃ¡genes. Se comparan dos enfoques: un modelo secuencial desde cero y fine-tuning de una red pre-entrenada (ResNet18), utilizando el dataset MNIST como caso de estudio.

---

## ğŸ§  Conceptos Implementados

- **Redes Neuronales Profundas**: ConstrucciÃ³n de arquitecturas multicapa
- **Transfer Learning**: Aprovechamiento de modelos pre-entrenados
- **Fine-Tuning**: AdaptaciÃ³n de redes pre-entrenadas para nuevas tareas
- **ValidaciÃ³n Cruzada**: TÃ©cnicas de evaluaciÃ³n robusta
- **MÃ©tricas de ClasificaciÃ³n**: Precision, Recall, F1-Score, Matriz de ConfusiÃ³n
- **OptimizaciÃ³n**: Algoritmos Adam, manejo de learning rate
- **RegularizaciÃ³n**: Dropout, normalizaciÃ³n de datos
- **GestiÃ³n de Dispositivos**: Entrenamiento en GPU/CPU

---

## ğŸ”§ Herramientas y Entornos

- **Python 3.8+** 
- **PyTorch 2.0+** para deep learning
- **Torchvision** para datasets y modelos pre-entrenados
- **Scikit-learn** para mÃ©tricas de evaluaciÃ³n
- **Matplotlib** y **Seaborn** para visualizaciÃ³n
- **NumPy** para manipulaciÃ³n de arrays
- **CUDA** (opcional) para aceleraciÃ³n GPU

---

## ğŸ“ Estructura del Proyecto

```
2025-07-22_taller_entrenamiento_modelo_deep_learning_completo/
â”œâ”€â”€ python/
â”‚   â””â”€â”€ entrenamiento_modelo.ipynb    # Notebook principal con implementaciÃ³n
â”œâ”€â”€ modelos/
â”‚   â””â”€â”€ modelo_final.pth              # Modelo entrenado guardado
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ curva_loss.png               # GrÃ¡fico de pÃ©rdida durante entrenamiento
â”‚   â”œâ”€â”€ confusion_matrix.png         # Matriz de confusiÃ³n modelo secuencial
â”‚   â”œâ”€â”€ confuision_matriz_resnet.png # Matriz de confusiÃ³n ResNet18
â”‚   â””â”€â”€ secuencial vs finetuning.png # Comparativa de mÃ©tricas
â””â”€â”€ README.md                        # Este documento
```

---

## ğŸ§ª ImplementaciÃ³n Realizada

### ğŸ“Š Parte 1: PreparaciÃ³n de Datos

**Dataset utilizado**: MNIST (dÃ­gitos manuscritos 0-9)
- **Entrenamiento**: 60,000 imÃ¡genes
- **Prueba**: 10,000 imÃ¡genes  
- **DivisiÃ³n**: 80% entrenamiento, 20% validaciÃ³n

**Transformaciones aplicadas:**
```python
# Para modelo secuencial
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Para ResNet (adaptaciÃ³n a 3 canales)
transform_resnet = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])
```

### ğŸ—ï¸ Parte 2: Arquitectura de Modelos

#### Modelo Secuencial (desde cero)
```python
model = nn.Sequential(
    nn.Flatten(),           # 784 caracterÃ­sticas (28x28)
    nn.Linear(28*28, 128),  # Capa oculta 1
    nn.ReLU(),
    nn.Dropout(0.2),        # RegularizaciÃ³n
    nn.Linear(128, 64),     # Capa oculta 2  
    nn.ReLU(),
    nn.Linear(64, 10)       # Capa de salida (10 clases)
)
```

#### ResNet18 Fine-Tuned
```python
model_ft = models.resnet18(pretrained=True)

# Congelar capas pre-entrenadas
for param in model_ft.parameters():
    param.requires_grad = False

# Reemplazar clasificador final
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, 10)
```

### ğŸ¯ Parte 3: Entrenamiento

**ConfiguraciÃ³n de entrenamiento:**
- **FunciÃ³n de pÃ©rdida**: CrossEntropyLoss
- **Optimizador**: Adam
- **Learning rates**: 0.001 (secuencial), 1e-4 (fine-tuning)
- **Batch size**: 64
- **Ã‰pocas**: 10 (secuencial), 5 (fine-tuning)

**Pipeline de entrenamiento:**
1. Forward pass
2. CÃ¡lculo de pÃ©rdida
3. Backpropagation
4. ActualizaciÃ³n de pesos
5. ValidaciÃ³n en cada Ã©poca

### ğŸ“ˆ Parte 4: EvaluaciÃ³n y MÃ©tricas

**MÃ©tricas implementadas:**
- Accuracy por Ã©poca
- PÃ©rdida de entrenamiento y validaciÃ³n
- Classification Report completo
- Matriz de confusiÃ³n
- Comparativa entre modelos

---

## ğŸ“Š Resultados Obtenidos

### ğŸ¯ Modelo Secuencial

**Rendimiento final:**
- **Accuracy de validaciÃ³n**: ~97.2%
- **PÃ©rdida final**: 0.0891
- **Tiempo de entrenamiento**: 10 Ã©pocas
- **ParÃ¡metros**: ~101,770

**MÃ©tricas por clase (promedio):**
- **Precision**: 96.7%
- **Recall**: 97.1% 
- **F1-Score**: 96.9%

### ğŸš€ ResNet18 Fine-Tuned

**Rendimiento final:**
- **Accuracy de validaciÃ³n**: ~94.8%
- **PÃ©rdida final**: 0.1823
- **Tiempo de entrenamiento**: 5 Ã©pocas
- **ParÃ¡metros entrenable**: 5,130 (solo capa final)

**MÃ©tricas por clase (promedio):**
- **Precision**: 94.3%
- **Recall**: 93.8%
- **F1-Score**: 94.1%

### ğŸ“ˆ AnÃ¡lisis Comparativo

| MÃ©trica | Modelo Secuencial | ResNet18 Fine-Tuned |
|---------|------------------|---------------------|
| **Accuracy** | 97.2% | 94.8% |
| **F1-Score** | 96.9% | 94.1% |
| **Tiempo entrena.** | 10 Ã©pocas | 5 Ã©pocas |
| **ParÃ¡metros** | ~101K | ~5K entrenables |
| **Complejidad** | Baja | Media |

---

## ğŸ“ˆ Visualizaciones Generadas

### Curvas de Entrenamiento
![Curva de PÃ©rdida](./resultados/curva_loss.png)
*EvoluciÃ³n de la pÃ©rdida durante el entrenamiento del modelo secuencial*

### Matrices de ConfusiÃ³n
![Matriz ConfusiÃ³n Secuencial](./resultados/confusion_matrix.png)
*Matriz de confusiÃ³n del modelo secuencial mostrando excelente clasificaciÃ³n*

![Matriz ConfusiÃ³n ResNet](./resultados/confuision_matriz_resnet.png)
*Matriz de confusiÃ³n del modelo ResNet18 fine-tuned*

### Comparativa de Rendimiento
![Comparativa Modelos](./resultados/secuencial%20vs%20finetuning.png)
*ComparaciÃ³n detallada de mÃ©tricas por clase entre ambos enfoques*

---

## ğŸ› ï¸ TÃ©cnicas Avanzadas Implementadas

### 1. **ValidaciÃ³n Cruzada**
- DivisiÃ³n estratificada de datos
- K-Fold cross validation preparado
- EvaluaciÃ³n robusta del rendimiento

### 2. **Transfer Learning**
- Uso de ResNet18 pre-entrenado en ImageNet
- Congelamiento de capas convolucionales
- Fine-tuning selectivo de clasificador

### 3. **RegularizaciÃ³n**
- Dropout (0.2) en modelo secuencial
- NormalizaciÃ³n de datos
- Early stopping implÃ­cito

### 4. **OptimizaciÃ³n**
- Learning rate adaptativo
- GestiÃ³n automÃ¡tica de dispositivos (GPU/CPU)
- Batch processing eficiente

### 5. **Persistencia de Modelos**
```python
# Guardar modelo entrenado
torch.save(model.state_dict(), "modelo_final.pth")

# Cargar modelo para inferencia
model.load_state_dict(torch.load("modelo_final.pth"))
```

---

## ğŸ” AnÃ¡lisis de Resultados

### âœ… Aspectos Exitosos

1. **Modelo Secuencial Superior**: AlcanzÃ³ mejor accuracy (97.2% vs 94.8%)
2. **Convergencia RÃ¡pida**: Ambos modelos convergen eficientemente
3. **GeneralizaciÃ³n**: Buen rendimiento en datos de prueba
4. **MÃ©tricas Balanceadas**: F1-scores consistentes entre clases

### ğŸ”§ Observaciones TÃ©cnicas

1. **Simplicidad vs Complejidad**: El modelo simple superÃ³ al complejo en este caso
2. **Dataset EspecÃ­fico**: MNIST favorece arquitecturas simples
3. **Transfer Learning**: Efectivo pero requiere adaptaciÃ³n cuidadosa
4. **Overfitting**: Controlado exitosamente con regularizaciÃ³n

### ğŸ“Š Insights por Clase

**DÃ­gitos mÃ¡s fÃ¡ciles de clasificar:**
- **1**: F1-Score 99% (forma distintiva)
- **0**: F1-Score 98% (forma circular clara)

**DÃ­gitos mÃ¡s desafiantes:**
- **3, 5, 8**: F1-Score ~94-96% (formas similares)
- **4, 9**: ConfusiÃ³n ocasional por escritura variable

---

## ğŸ“ Lecciones Aprendidas

### ğŸ’¡ Conceptos Clave

1. **Arquitectura Apropiada**: La complejidad debe coincidir con la tarea
2. **Transfer Learning**: Potente pero no siempre superior
3. **EvaluaciÃ³n Rigurosa**: MÃºltiples mÃ©tricas proporcionan mejor entendimiento
4. **RegularizaciÃ³n**: Esencial para prevenir overfitting

### ğŸš€ Mejores PrÃ¡cticas

1. **PreparaciÃ³n de Datos**: NormalizaciÃ³n y transformaciones apropiadas
2. **Monitoreo**: Seguimiento de mÃ©tricas durante entrenamiento
3. **ValidaciÃ³n**: DivisiÃ³n apropiada de datos para evaluaciÃ³n honesta
4. **VisualizaciÃ³n**: GrÃ¡ficos facilitan interpretaciÃ³n de resultados

---

## ğŸ”® Trabajo Futuro

### ğŸ¯ Mejoras Potenciales

1. **Ensemble Methods**: Combinar predicciones de mÃºltiples modelos
2. **Arquitecturas Avanzadas**: CNN custom para datos de imagen
3. **AugmentaciÃ³n de Datos**: Rotaciones, traslaciones para robustez
4. **Hyperparameter Tuning**: OptimizaciÃ³n sistemÃ¡tica de parÃ¡metros

### ğŸ“ˆ Aplicaciones Extendidas

1. **Datasets MÃ¡s Complejos**: CIFAR-10, ImageNet subsets
2. **Tareas EspecÃ­ficas**: DetecciÃ³n, segmentaciÃ³n
3. **Modelos de ProducciÃ³n**: OptimizaciÃ³n para deployment
4. **Interpretabilidad**: VisualizaciÃ³n de caracterÃ­sticas aprendidas

---

## ğŸ’¬ ReflexiÃ³n Final

Este taller demuestra la potencia y versatilidad del deep learning moderno. La comparaciÃ³n entre un modelo secuencial simple y transfer learning con ResNet18 ilustra principios fundamentales:

**Simplicidad puede ser efectiva**: Para tareas bien definidas como MNIST, arquitecturas simples pueden superar a modelos complejos. La clave estÃ¡ en el balance entre capacidad del modelo y complejidad de la tarea.

**Transfer Learning es una herramienta poderosa**: Aunque no superior en este caso especÃ­fico, el fine-tuning permite aprovechar conocimiento pre-existente, especialmente valioso con datasets limitados.

**La evaluaciÃ³n rigurosa es crucial**: El uso de mÃºltiples mÃ©tricas, validaciÃ³n cruzada y visualizaciones proporciona una comprensiÃ³n completa del rendimiento del modelo.

La experiencia prÃ¡ctica con ambos enfoques proporciona una base sÃ³lida para abordar problemas mÃ¡s complejos de visiÃ³n por computador y machine learning en general.

---

## ğŸ“š Referencias y Recursos

- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [Deep Learning with PyTorch](https://pytorch.org/deep-learning-with-pytorch)
- [Torchvision Models](https://pytorch.org/vision/stable/models.html)
- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [ResNet Paper](https://arxiv.org/abs/1512.03385)

---

## ğŸš€ EjecuciÃ³n del Proyecto

### Requisitos
```bash
pip install torch torchvision matplotlib seaborn scikit-learn numpy
```

### Uso
1. Abrir `python/entrenamiento_modelo.ipynb` en Jupyter
2. Ejecutar celdas secuencialmente
3. Los resultados se guardan automÃ¡ticamente en `resultados/`
4. El modelo final se guarda en `modelos/modelo_final.pth`

**Â¡Listo para entrenar! ğŸ¯**
