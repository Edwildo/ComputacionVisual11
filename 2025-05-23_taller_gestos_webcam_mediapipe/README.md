# Taller: Gestos con C√°mara Web ‚Äì Control Visual con MediaPipe

**Fecha:** 2025-05-23

## üìã Descripci√≥n general

En este taller usaremos la webcam y la librer√≠a MediaPipe para detectar gestos de mano en tiempo real y ejecutar acciones visuales con OpenCV. Aprender√°s a crear una interfaz natural que reaccione al n√∫mero de dedos extendidos y a la distancia entre puntos de referencia de la mano.

---

## üóÇÔ∏è Estructura de carpetas

```
2025-05-23_taller_gestos_webcam_mediapipe/
‚îú‚îÄ‚îÄ python/                # Notebooks o scripts .py
‚îÇ   ‚îî‚îÄ‚îÄ hand_gestures.py   # Implementaci√≥n principal
‚îî‚îÄ‚îÄ README.md              # Documentaci√≥n del taller
```

---

## üéØ Objetivos

* Capturar video de la webcam en tiempo real con OpenCV.
* Detectar la posici√≥n de las manos usando MediaPipe Hands.
* Medir:

  * N√∫mero de dedos extendidos.
  * Distancia entre el √≠ndice y el pulgar.
* Generar respuestas visuales basadas en gestos (cambio de color, movimiento de objetos, cambio de escena).

---

## üíª Python ‚Äì Notebook / Script

En `python/hand_gestures.py` (o Notebook) implementa:

1. **Inicializaci√≥n**

   ```python
   import cv2
   from mediapipe import solutions
   import numpy as np

   cap = cv2.VideoCapture(0)
   hands = solutions.hands.Hands(min_detection_confidence=0.7,
                                 min_tracking_confidence=0.5)
   mp_draw = solutions.drawing_utils
   ```

2. **Loop principal**

   ```python
   while True:
       ret, frame = cap.read()
       if not ret: break
       img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
       results = hands.process(img_rgb)

       if results.multi_hand_landmarks:
           for handLms in results.multi_hand_landmarks:
               mp_draw.draw_landmarks(frame, handLms, solutions.hands.HAND_CONNECTIONS)
               # Extraer coordenadas de dedos
               # Calcular n√∫mero de dedos arriba
               # Calcular distancia √≠ndice-pulgar
               # Acciones visuales seg√∫n condici√≥n
       cv2.imshow("Gestos WebCam", frame)
       if cv2.waitKey(1) & 0xFF == 27: break
   cap.release()
   cv2.destroyAllWindows()
   ```

3. **Detecci√≥n de dedos**

   * Compara la posici√≥n de cada punta de dedo con su articulaci√≥n inferior.
   * Suma cu√°ntos est√°n extendidos.

4. **Distancia entre √≠ndice y pulgar**

   ```python
   idx = handLms.landmark[solutions.hands.HandLandmark.INDEX_FINGER_TIP]
   thumb = handLms.landmark[solutions.hands.HandLandmark.THUMB_TIP]
   dist = np.linalg.norm(np.array([idx.x, idx.y]) - np.array([thumb.x, thumb.y]))
   ```

5. **Acciones visuales**

   * Si 5 dedos: fondo verde.
   * Si distancia < umbral: dibuja un c√≠rculo rojo.
   * Gestos compuestos para cambiar de escena o mover un sprite.

---

## üìö Entrega y evidencias

* **GIFs** animados mostrando cada gesto y su respuesta visual.
* **Explicaci√≥n** breve de c√≥mo funciona MediaPipe Hands y los gestos implementados.
* **Prompts** utilizados (si se apoy√≥ en prompts o documentaci√≥n externa).
* **Reflexi√≥n** sobre precisi√≥n, latencia y mejoras posibles (filtrado de ruido, calibraci√≥n).

---

‚úÖ ¬°Listo para comenzar! Realiza commits descriptivos en ingl√©s, documenta tu c√≥digo y prepara evidencias gr√°ficas para el repositorio.
